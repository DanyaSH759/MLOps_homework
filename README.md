# ML_homework

## Структура проект

```
.
├── .git
│   ├── COMMIT_EDITMSG
│   ├── FETCH_HEAD
│   ├── HEAD
│   ├── ORIG_HEAD
│   ├── branches
│   ├── config
│   ├── description
│   ├── hooks
│   ├── index
│   ├── info
│   ├── logs
│   ├── objects
│   ├── packed-refs
│   └── refs
├── .gitignore
├── .pre-commit-config.yaml
├── 953617865023309975
│   └── 6d192f55aa3646c38e5a5ae0aca57006
├── Dockerfile
├── README.md
├── configs
│   ├── infer.yaml
│   └── train.yaml
├── data
│   └── Прошлые_данныеCSV.csv
├── docker-compose.yml
├── info_project
│   ├── project_structure.txt
│   └── чеклист_команд.txt
├── mlruns
│   ├── .trash
│   └── 0
├── outputs
│   └── 2025-01-05
├── poetry.lock
├── predict
│   └── predictions_20250104_143552.csv
├── pyproject.toml
├── scripts
│   ├── infer.py
│   └── train.py
└── venv
    ├── bin
    ├── generated
    ├── include
    ├── lib
    ├── lib64 -> lib
    ├── pyvenv.cfg
    └── share

```
Описание структур: 
- pyproject.toml, poetry.lock, .gitignore , .pre-commit-config.yaml - конфигурационные файлы окружения и файлы для работы с git
- В папек scripts файлы infer.py и train.py - основные исполняемые py файлы для обучения и предсказания модели соответственно
- Папка outputs - формируется атоматически hydra-core после запуска обучения модели с логами ответа в консоли
- docker-compose.yml и Dockerfile билды контейренов для дальнейшего использования кода
- Папка data - где хранится датасет, папка predict - сохранение резултатов предсказания
- Папка configs хранит в себе соновные конфиги train.yaml и infer.yaml используемые в скриптах py соответственно






## Задача проект

Необходимо сформировать автоматизированное решение по обучению/дообучению модели
нейронной модели для решения задачи регресси, а иенно для предсказания стоимости
на криптовалюты.

## Варианты сбора данных

Варианты сбора данных:

- Написание собственно парсера для сбора информации (для итогового дипломного
  проекта)
- Скачивание выборок в формате csv с платформа агрегаторов, к примеру
  https://www.bitget.com/ru/price/bitcoin/historical-data
- Использование API для сбора информации https://www.coingecko.com/ru/api

Полученных данных будет достаточно для предсказание временных рядов.

## Получение данных

На текущий момент данные скачиваются с сайта https://www.bitget.com/ru/price/bitcoin/historical-data
Используемые поля:
- дата
- цена
- цена открытия
- цена закрытия
- макс. цена в день торгов
- мин. цена в день торгов
- объём продаж
- % изменения стоимости 


## Минусы/проблемы при сборе данных

- Есть зависимость от ручной загрузки данных
- Платные API Для получения актуальной информации
- Не учитываются влияние на рынок внешних факторов, что крайне важно для
  финансовых активов

## Используемые модели

Т.к. стоит условие "использовать только нейросети", в данном проекте будет
обученна нейросеть в питорче для решения задачи регрессии. (P.S. В целом можно
было заметить, что оснавная задача проекта связана с временными рядами, а не с
задачей регресии, это сильноо упрощение я допускаю целенаправлено, что бы
ускорить темп подготовки и сдачи дз)


# Инструкция по запуску проекта

Т.к. используется логирование эксперементов через MLflow есть некторые неудобные моменты с установкой связи между контейнерами. Поэтому основной код проекта рекомендуется запускать через виртуальное окружение.

## Поднятие локального окружения (в примере используется Ubutnu 22.04)

- Скачиваем плностью весь проект 
- Прописываем в консоли ```python3 -m venv venv```
- Прописываем в консоли```source venv/bin/activate```
- Прописываем в консоли ```pip install -U pip setuptools```
- Прописываем в консоли ```pip install poetry```
- Прописываем в консоли ```pip install -r requirements.txt```
- done

## Поднимаем mlflow

- Если есть кредиты на S3 для поднятия бакета, то заполняем в файле  ```docker compose -f docker-compose.yml up``` поля
- - ```
    AWS_ACCESS_KEY_ID: ....
    AWS_SECRET_ACCESS_KEY: ...
    ...
    mlflow server --host 0.0.0.0 \
            --default-artifact-root s3://.... --serve-artifacts

    ```
- Прописываем ```docker compose -f docker-compose.yml up```
- Проверяем что сервис поднялся на ```http://127.0.0.1:5050/```
- done

## Запуск тренировки модели

- Настраиваем нужные нам параметры для модели в ```configs/train.yaml```
- Прописываем в консоли (в активном виртуальном окружении и кореновй папке проекта) ```python scripts/train.py```
- Если возникнет проблема по типу ```PermissionError: [Errno 13] Permission denied: 'outputs/2025-01-05/20-00-06'``` то прописываем в консоли ```sudo chmod -R 777 outputs```
sudo chmod -R 777 mlruns
- 
- done

## Использование модели
p.s. сейчас модель использует тестовую выборку из общего датасета.

- Корректируем данные в ```configs/infer.yaml``` в соответстиви с тем что было использовано в ```train.yaml```
- Полсе обучения mlflow создает папку эксперемента (для примера уже загружена одна такая папка с длинным уникальным номером, в котором лежит обученная модель)
- После обучения модели, необходимо выбрать модель из сформированной папки эксперемента mlflow и прописать путь в поле checkpoint_path в infer.yaml . Например вот так ```checkpoint_path: "/home/danila/mainpk/MLOPS_next/test_mlopspr/MLOps_homework/953617865023309975/6d192f55aa3646c38e5a5ae0aca57006/checkpoints/epoch=499-step=1500.ckpt"```
- Прописываем в консоли ```python scripts/infer.py```
- Предсказания сохранились в папку predict
- done






